
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Segundo resumen sobre modelos de clasificación supervisada &#8212; Introducción a Machine Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Cuadernos/Modelos de Clasificación II';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Algoritmos Clúster" href="Ejercicio%20K%20Means.html" />
    <link rel="prev" title="Primer resumen sobre modelos de clasificación supervisada" href="Modelos%20de%20Clasificaci%C3%B3n%20I.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="introduccion.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introducción a Machine Learning - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introducción a Machine Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="introduccion.html">
                    Introducción al Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Intro%20a%20Python%20y%20Pandas.html">Introducción a Python y Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="Minutos%20y%20segundos.html">Uso de Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="Graficos.html">Trabajemos en algunos gráficos</a></li>
<li class="toctree-l1"><a class="reference internal" href="Medidas%20Estadisticas.html">Medidas estadísticas</a></li>
<li class="toctree-l1"><a class="reference internal" href="Visualizaci%C3%B3n%20en%20Python.html">Visualización de datos con Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="Manipulaci%C3%B3n%2C%20Limpieza%20y%20Exploraci%C3%B3n%20de%20Datos.html">Manipulación, Limpieza y Exploración de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="Aprendizaje%20Autom%C3%A1tico.html">Introducción al Aprendizaje Automático en Mercadeo</a></li>
<li class="toctree-l1"><a class="reference internal" href="Estadisticos%20de%20Validaci%C3%B3n.html">Estadísticos de Validación de un Modelo de Clasificación Supervisada</a></li>
<li class="toctree-l1"><a class="reference internal" href="Modelos%20de%20Clasificaci%C3%B3n%20I.html">Primer resumen sobre modelos de clasificación supervisada</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Segundo resumen sobre modelos de clasificación supervisada</a></li>
<li class="toctree-l1"><a class="reference internal" href="Ejercicio%20K%20Means.html">Algoritmos Clúster</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Izainea/seminario-de-programacion" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Izainea/seminario-de-programacion/issues/new?title=Issue%20on%20page%20%2FCuadernos/Modelos de Clasificación II.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Cuadernos/Modelos de Clasificación II.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Segundo resumen sobre modelos de clasificación supervisada</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-support-vector-machines-svm">Cómo Funciona Support Vector Machines (SVM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principios-fundamentales-de-svm">Principios Fundamentales de SVM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-algoritmo-svm">Visualización del Algoritmo SVM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-importantes-de-svm">Hipérparámetros Importantes de SVM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-naive-bayes">Cómo Funciona Naive Bayes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentos-detallados-de-naive-bayes">Fundamentos Detallados de Naive Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-extendidas-de-naive-bayes">Aplicaciones Extendidas de Naive Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-intuitivo-y-visual">Ejemplo Intuitivo y Visual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-de-naive-bayes">Hiperparámetros de Naive Bayes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-gradient-boosting">Cómo Funciona Gradient Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principios-fundamentales-de-gradient-boosting">Principios Fundamentales de Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-algoritmo-gradient-boosting">Visualización del Algoritmo Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-y-ventajas-de-gradient-boosting">Aplicaciones y Ventajas de Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-importantes-de-gradient-boosting">Hiperparámetros Importantes de Gradient Boosting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funcionan-las-redes-neuronales-artificiales">Cómo Funcionan las Redes Neuronales Artificiales</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principios-fundamentales-de-las-redes-neuronales">Principios Fundamentales de las Redes Neuronales</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entrenamiento-de-redes-neuronales">Entrenamiento de Redes Neuronales</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-y-ventajas-de-las-redes-neuronales">Aplicaciones y Ventajas de las Redes Neuronales</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones">Conclusiones</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="segundo-resumen-sobre-modelos-de-clasificacion-supervisada">
<h1>Segundo resumen sobre modelos de clasificación supervisada<a class="headerlink" href="#segundo-resumen-sobre-modelos-de-clasificacion-supervisada" title="Link to this heading">#</a></h1>
<p>En este capítulo, revisaremos los modelos de clasificación que no se vieron en el primer resumen. Veremos los siguientes modelos:</p>
<ul class="simple">
<li><p>Support Vector Machines (SVM)</p></li>
<li><p>Naive Bayes</p></li>
<li><p>Gradient Boosting</p></li>
<li><p>Redes Neuronales Artificiales</p></li>
</ul>
<p>Como en el anterior capítulo, no solo cubriremos la teoría y la intuición detrás de Random Forest y otros métodos de clasificación supervisada, sino que también proporcionaremos ejemplos prácticos y ejercicios en Python. Utilizaremos librerías populares como scikit-learn, que ofrece implementaciones eficientes y fáciles de usar de una variedad de algoritmos de aprendizaje automático.</p>
<p>Cada uno de estos modelos tiene sus propias fortalezas y situaciones en las que es más adecuado. A lo largo de este capítulo, exploraremos en detalle cómo cada uno funciona, cómo se implementan en Python utilizando scikit-learn u otras bibliotecas relevantes, y en qué situaciones podrían ser la mejor opción para tus proyectos de clasificación supervisada.</p>
<p>Recordemos la estructura abstracta para entrenar modelos en scikit-learn:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sintaxis General para Modelos de Clasificación en Scikit-learn</p>
<p>En scikit-learn, la implementación de modelos de clasificación supervisada sigue un patrón consistente, lo que facilita la experimentación con diferentes algoritmos. Este patrón se puede describir en unos pocos pasos generales aplicables a cualquier modelo de clasificación. Aquí te muestro cómo se ve esta sintaxis de manera abstracta:</p>
<h3 class="rubric" id="pasos-generales">Pasos Generales</h3>
<ol class="arabic">
<li><p><strong>Importar el Modelo:</strong> Primero, se importa la clase correspondiente al modelo que deseas utilizar desde scikit-learn.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.</span><span class="p">[</span><span class="n">modulo</span><span class="p">]</span> <span class="kn">import</span> <span class="p">[</span><span class="n">Modelo</span><span class="p">]</span>
</pre></div>
</div>
</li>
<li><p><strong>Instanciar el Modelo:</strong> Creas una instancia del modelo, donde puedes especificar varios hiperparámetros según tus necesidades. Si no estás seguro, puedes empezar con los valores predeterminados.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">modelo</span> <span class="o">=</span> <span class="p">[</span><span class="n">Modelo</span><span class="p">](</span><span class="n">hiperparametro1</span><span class="o">=</span><span class="n">valor1</span><span class="p">,</span> <span class="n">hiperparametro2</span><span class="o">=</span><span class="n">valor2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Entrenar el Modelo:</strong> Utilizas el método <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> para entrenar el modelo con tus datos de entrenamiento. Esto ajustará los parámetros del modelo para minimizar el error de predicción.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Hacer Predicciones:</strong> Una vez entrenado el modelo, puedes usar el método <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> para hacer predicciones sobre nuevos datos.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<p><strong>Ejemplo Genérico</strong></p>
<p>Aquí tienes un ejemplo genérico que muestra cómo aplicar estos pasos:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Paso 1: Importar el modelo</span>
<span class="kn">from</span> <span class="nn">sklearn.</span><span class="p">[</span><span class="n">modulo</span><span class="p">]</span> <span class="kn">import</span> <span class="p">[</span><span class="n">Modelo</span><span class="p">]</span>

<span class="c1"># Paso 2: Instanciar el modelo con los hiperparámetros deseados</span>
<span class="n">modelo</span> <span class="o">=</span> <span class="p">[</span><span class="n">Modelo</span><span class="p">](</span><span class="n">hiperparametro1</span><span class="o">=</span><span class="n">valor1</span><span class="p">,</span> <span class="n">hiperparametro2</span><span class="o">=</span><span class="n">valor2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>

<span class="c1"># Paso 3: Entrenar el modelo</span>
<span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Paso 4: Hacer predicciones</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Es importante recordar que <code class="docutils literal notranslate"><span class="pre">[modulo]</span></code>, <code class="docutils literal notranslate"><span class="pre">[Modelo]</span></code>, <code class="docutils literal notranslate"><span class="pre">hiperparametro1</span></code>, <code class="docutils literal notranslate"><span class="pre">valor1</span></code>, etc., son marcadores de posición. Deben reemplazarce con los nombres específicos y valores relevantes para el modelo que estás utilizando. Esta estructura te permite adaptar fácilmente el código para diferentes modelos de clasificación supervisada en scikit-learn.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<section id="como-funciona-support-vector-machines-svm">
<h2>Cómo Funciona Support Vector Machines (SVM)<a class="headerlink" href="#como-funciona-support-vector-machines-svm" title="Link to this heading">#</a></h2>
<p>Support Vector Machines (SVM) representa uno de los algoritmos más robustos y precisos dentro del aprendizaje supervisado, especialmente utilizado para problemas de clasificación. Este algoritmo se basa en la idea de encontrar el mejor hiperplano que separa las distintas clases en el espacio de características.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>El hiperplano en el contexto de SVM es conceptualmente similar a una línea de división en 2D, pero extendido a espacios de mayor dimensión. Su objetivo es maximizar el margen entre las clases de datos, siendo este margen la distancia mínima entre el hiperplano y los puntos más cercanos de las clases (vectores de soporte).</p>
</div>
<section id="principios-fundamentales-de-svm">
<h3>Principios Fundamentales de SVM<a class="headerlink" href="#principios-fundamentales-de-svm" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Identificación del Mejor Hiperplano:</strong> SVM comienza el proceso de clasificación buscando el hiperplano que ofrece la mayor separación (margen) entre las diferentes clases. En un espacio de dos dimensiones, este hiperplano puede visualizarse como una línea.</p></li>
<li><p><strong>Maximización del Margen:</strong> El margen se define como la distancia entre el hiperplano y los vectores de soporte más cercanos. Los vectores de soporte son aquellos puntos de datos que están más cerca del hiperplano. SVM optimiza este margen para mejorar la capacidad del modelo para generalizar bien a nuevos datos.</p></li>
<li><p><strong>Uso del Truco del Kernel:</strong> En situaciones donde los datos no son linealmente separables, SVM utiliza técnicas de kernel para transformar el espacio de entrada en un espacio de mayor dimensión donde los datos pueden ser separados linealmente. Esto permite a SVM manejar eficazmente relaciones complejas y no lineales entre las características.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A través del truco del kernel, SVM es capaz de realizar clasificaciones complejas y no lineales utilizando espacios de características transformados, sin necesidad de calcular explícitamente las dimensiones adicionales.</p>
</div>
</section>
<section id="visualizacion-del-algoritmo-svm">
<h3>Visualización del Algoritmo SVM<a class="headerlink" href="#visualizacion-del-algoritmo-svm" title="Link to this heading">#</a></h3>
<p>Imagina que estás en un campo abierto donde se encuentran dispersos dos tipos de flores. Tu tarea es trazar una línea recta (en este caso, el hiperplano) que separe lo mejor posible estos dos tipos de flores. El enfoque de SVM no solo se centra en trazar esta línea sino en posicionarla de tal manera que la distancia (margen) entre la línea y las flores más cercanas a ella (de ambos tipos) sea la máxima posible. Esto es equivalente a maximizar la tolerancia al error en la clasificación de futuras muestras de flores.</p>
<img alt="Support Vector Machines" class="align-center" src="../_images/SVM.png" />
<img alt="Support Vector Machines Algorithm" class="align-center" src="../_images/SVM_2.png" />
<p>SVM se destaca por su efectividad en espacios de alta dimensión y su capacidad para manejar fronteras de decisión complejas y no lineales, gracias al uso de funciones kernel. Este enfoque, centrado en la maximización del margen y en la importancia crítica de los vectores de soporte, permite que SVM sea altamente efectivo y preciso en la clasificación, incluso en situaciones donde la relación entre las características no es inmediatamente evidente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Importamos warnings para evitar los mensajes de advertencia</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1">## Ejemplo sencillo </span>

<span class="c1">## Dataset de prueba [Iris]</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">iris_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)],</span>
                        <span class="n">columns</span><span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>

<span class="n">iris_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>target
0    50
1    50
2    50
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Dividir el dataset en entrenamiento y prueba</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">iris_df</span><span class="p">[</span><span class="n">iris</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]],</span> <span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">],</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">iris_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X train shape:&#39;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X test shape:&#39;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X train shape: (90, 4)
X test shape: (60, 4)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Ahora clasificación con SVM</span>

<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1">## Predicción</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">## Evaluación</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        20
         1.0       1.00      1.00      1.00        20
         2.0       1.00      1.00      1.00        20

    accuracy                           1.00        60
   macro avg       1.00      1.00      1.00        60
weighted avg       1.00      1.00      1.00        60
</pre></div>
</div>
</div>
</div>
</section>
<section id="hiperparametros-importantes-de-svm">
<h3>Hipérparámetros Importantes de SVM<a class="headerlink" href="#hiperparametros-importantes-de-svm" title="Link to this heading">#</a></h3>
<p>SVM tiene varios hiperparámetros que pueden ajustarse para mejorar el rendimiento del modelo. <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> proporciona valores predeterminados razonables para estos hiperparámetros, pero es importante comprender cómo afectan al modelo. Algunos de los hiperparámetros más importantes de SVM son:</p>
<ul class="simple">
<li><p><strong>c:</strong> Parámetro de regularización que controla la compensación entre la maximización del margen y la minimización de la clasificación incorrecta. Un valor más alto de <code class="docutils literal notranslate"><span class="pre">C</span></code> dará como resultado un margen más estrecho pero una clasificación más precisa.</p></li>
<li><p><strong>kernel:</strong> Especifica el tipo de kernel a utilizar en la transformación de los datos. Los kernels comunes incluyen <code class="docutils literal notranslate"><span class="pre">linear</span></code>, <code class="docutils literal notranslate"><span class="pre">poly</span></code>, <code class="docutils literal notranslate"><span class="pre">rbf</span></code> (radial basis function), y <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>.</p></li>
<li><p><strong>gamma:</strong> Coeficiente del kernel para los kernels <code class="docutils literal notranslate"><span class="pre">rbf</span></code>, <code class="docutils literal notranslate"><span class="pre">poly</span></code>, y <code class="docutils literal notranslate"><span class="pre">sigmoid</span></code>. Un valor más alto de <code class="docutils literal notranslate"><span class="pre">gamma</span></code> dará como resultado un ajuste más preciso a los datos de entrenamiento, pero puede llevar a un sobreajuste.</p></li>
</ul>
</section>
</section>
<section id="como-funciona-naive-bayes">
<h2>Cómo Funciona Naive Bayes<a class="headerlink" href="#como-funciona-naive-bayes" title="Link to this heading">#</a></h2>
<p>Naive Bayes es un clasificador probabilístico que se basa en el teorema de Bayes, junto con una suposición simplificadora pero poderosa: la independencia condicional entre cada par de características dada la variable de clase. Este clasificador es ampliamente utilizado en tareas de clasificación debido a su simplicidad, eficiencia y efectividad, especialmente en el procesamiento de texto y filtrado de spam.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>El corazón de Naive Bayes es el teorema de Bayes, que permite calcular la probabilidad posterior de una clase, dadas ciertas características observadas, utilizando la probabilidad previa de la clase y las probabilidades de esas características dada la clase.</p>
</div>
<section id="fundamentos-detallados-de-naive-bayes">
<h3>Fundamentos Detallados de Naive Bayes<a class="headerlink" href="#fundamentos-detallados-de-naive-bayes" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Teorema de Bayes:</strong> Este teorema es esencial para entender cómo Naive Bayes actualiza las probabilidades de las hipótesis a medida que se dispone de nueva evidencia. Matemáticamente, el teorema se expresa como (P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}), donde (P(A|B)) es la probabilidad de (A) dado (B).</p></li>
<li><p><strong>Independencia de las Características:</strong> A pesar de que en la realidad las características pueden estar relacionadas, Naive Bayes simplifica los cálculos asumiendo que son independientes entre sí dada la clase. Esta suposición naive permite que el modelo se entrene y ejecute eficientemente incluso en conjuntos de datos de alta dimensión.</p></li>
<li><p><strong>Cálculo de Probabilidades:</strong> Naive Bayes calcula la probabilidad de cada clase dadas las características observadas y selecciona la clase con la mayor probabilidad como la predicción. Este proceso implica multiplicar las probabilidades de las características observadas, ajustadas por las probabilidades previas de las clases.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Aunque la suposición de independencia puede parecer una gran simplificación, Naive Bayes funciona sorprendentemente bien en muchos escenarios reales. Esto se debe a que, para la tarea de clasificación, lo que importa es la probabilidad relativa de las clases, no el valor exacto de las probabilidades.</p>
</div>
</section>
<section id="aplicaciones-extendidas-de-naive-bayes">
<h3>Aplicaciones Extendidas de Naive Bayes<a class="headerlink" href="#aplicaciones-extendidas-de-naive-bayes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Clasificación de Textos y Filtrado de Spam:</strong> Distinguir entre correos electrónicos legítimos y no deseados basándose en la presencia de ciertas palabras clave.</p></li>
<li><p><strong>Diagnóstico Médico:</strong> Predecir la presencia de enfermedades a partir de síntomas y resultados de pruebas, tratando cada síntoma o resultado de prueba como una característica independiente.</p></li>
<li><p><strong>Detección de Sentimientos en Textos:</strong> Determinar si una opinión expresada en texto es positiva, negativa o neutral, analizando las palabras y frases utilizadas.</p></li>
</ul>
</section>
<section id="ejemplo-intuitivo-y-visual">
<h3>Ejemplo Intuitivo y Visual<a class="headerlink" href="#ejemplo-intuitivo-y-visual" title="Link to this heading">#</a></h3>
<p>Considera el problema de clasificar animales en “gatos” y “perros” basado en características como “tamaño” y “sonido”. Naive Bayes miraría cada característica individualmente, calculando cómo afecta la probabilidad de que el animal sea un gato o un perro, sin preocuparse por las correlaciones entre “tamaño” y “sonido”. Si históricamente los animales pequeños que maúllan son más a menudo gatos, Naive Bayes inclinará fuertemente su predicción hacia “gato” cuando se encuentre con un animal pequeño que maúlla, independientemente de otras correlaciones.</p>
<p>Naive Bayes demuestra que incluso bajo suposiciones simplificadoras, se pueden desarrollar modelos poderosos y eficientes para clasificación. Su rendimiento, especialmente en tareas de clasificación de texto y situaciones con conjuntos de datos de alta dimensión, subraya la importancia de las técnicas probabilísticas en el aprendizaje automático y la ciencia de datos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo de Implementación con Naive Bayes en scikit-learn</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="c1"># Crear y entrenar el modelo Naive Bayes</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Realizar predicciones y evaluar el modelo</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluación</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        20
         1.0       0.95      0.95      0.95        20
         2.0       0.95      0.95      0.95        20

    accuracy                           0.97        60
   macro avg       0.97      0.97      0.97        60
weighted avg       0.97      0.97      0.97        60
</pre></div>
</div>
</div>
</div>
</section>
<section id="hiperparametros-de-naive-bayes">
<h3>Hiperparámetros de Naive Bayes<a class="headerlink" href="#hiperparametros-de-naive-bayes" title="Link to this heading">#</a></h3>
<p>Aunque Naive Bayes es un modelo relativamente simple, tiene algunos hiperparámetros que pueden ajustarse para mejorar su rendimiento. Algunos de los hiperparámetros más comunes son:</p>
<ul class="simple">
<li><p><strong>alpha:</strong> Parámetro de suavizado de Laplace, que evita la probabilidad cero para características no observadas en el conjunto de entrenamiento. Un valor más alto de <code class="docutils literal notranslate"><span class="pre">alpha</span></code> suaviza las estimaciones de probabilidad, lo que puede ser útil para evitar el sobreajuste.</p></li>
<li><p><strong>fit_prior:</strong> Indica si se deben aprender las probabilidades previas de las clases a partir de los datos de entrenamiento. Si se establece en <code class="docutils literal notranslate"><span class="pre">False</span></code>, se utilizarán probabilidades previas uniformes.</p></li>
<li><p><strong>class_prior:</strong> Proporciona probabilidades previas específicas de las clases. Si no se especifica, se utilizarán probabilidades previas uniformes.</p></li>
</ul>
</section>
</section>
<section id="como-funciona-gradient-boosting">
<h2>Cómo Funciona Gradient Boosting<a class="headerlink" href="#como-funciona-gradient-boosting" title="Link to this heading">#</a></h2>
<p>Gradient Boosting es una técnica de aprendizaje automático que construye un modelo predictivo en forma de un conjunto de modelos de predicción débiles, generalmente árboles de decisión. A diferencia de Random Forest, que entrena cada árbol de forma independiente, Gradient Boosting entrena cada árbol de forma secuencial, mejorando los errores de los árboles anteriores.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>El término “Gradient Boosting” se refiere a la técnica de optimización utilizada para minimizar la función de pérdida del modelo, ajustando los parámetros del modelo en la dirección que reduce el gradiente de la función de pérdida.</p>
</div>
<section id="principios-fundamentales-de-gradient-boosting">
<h3>Principios Fundamentales de Gradient Boosting<a class="headerlink" href="#principios-fundamentales-de-gradient-boosting" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Modelos de Predicción Débiles:</strong> En Gradient Boosting, los modelos de predicción débiles, como árboles de decisión poco profundos, se combinan para formar un modelo más fuerte. Cada árbol se enfoca en corregir los errores de los árboles anteriores, en lugar de predecir directamente la variable objetivo.</p></li>
<li><p><strong>Optimización Secuencial:</strong> A diferencia de Random Forest, donde los árboles se entrenan de forma independiente, en Gradient Boosting, los árboles se entrenan secuencialmente. Cada árbol se ajusta para minimizar la función de pérdida del modelo, que mide la diferencia entre las predicciones del modelo y los valores reales.</p></li>
<li><p><strong>Uso de Gradientes:</strong> El algoritmo de Gradient Boosting utiliza gradientes de la función de pérdida para ajustar los parámetros del modelo en la dirección que minimiza la pérdida. Este enfoque de optimización basado en gradientes permite que el modelo mejore gradualmente a medida que se agregan más árboles.</p></li>
</ol>
</section>
<section id="visualizacion-del-algoritmo-gradient-boosting">
<h3>Visualización del Algoritmo Gradient Boosting<a class="headerlink" href="#visualizacion-del-algoritmo-gradient-boosting" title="Link to this heading">#</a></h3>
<p>Imagina que estás subiendo una colina y quieres llegar a la cima lo más rápido posible. En lugar de elegir la ruta más corta de antemano, decides dar pequeños pasos en la dirección que te lleva más alto en cada paso. Este enfoque te permite avanzar gradualmente hacia la cima, incluso si no puedes ver la cima desde tu posición actual.</p>
<img alt="Gradient Boosting Algorithm" class="align-center" src="Cuadernos/images/Gradient_Boosting.png" />
<p>Gradient Boosting sigue un enfoque similar, mejorando el modelo de forma incremental en lugar de intentar ajustar todos los parámetros de una vez. Cada árbol de decisión se enfoca en corregir los errores de los árboles anteriores, lo que resulta en un modelo final que es una combinación ponderada de todos los árboles.</p>
</section>
<section id="aplicaciones-y-ventajas-de-gradient-boosting">
<h3>Aplicaciones y Ventajas de Gradient Boosting<a class="headerlink" href="#aplicaciones-y-ventajas-de-gradient-boosting" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Clasificación y Regresión:</strong> Gradient Boosting es efectivo tanto para problemas de clasificación como de regresión, y es especialmente útil cuando se requiere un alto nivel de precisión.</p></li>
<li><p><strong>Manejo de Datos Desbalanceados:</strong> Debido a su capacidad para ajustar los errores de los modelos anteriores, Gradient Boosting puede manejar eficazmente conjuntos de datos desbalanceados.</p></li>
<li><p><strong>Interpretación de Características:</strong> Aunque Gradient Boosting es un modelo complejo, se pueden utilizar técnicas como la importancia de las características para comprender qué características son más influyentes en las predicciones.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Implementación de gradient boosting</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        20
         1.0       0.95      0.95      0.95        20
         2.0       0.95      0.95      0.95        20

    accuracy                           0.97        60
   macro avg       0.97      0.97      0.97        60
weighted avg       0.97      0.97      0.97        60
</pre></div>
</div>
</div>
</div>
</section>
<section id="hiperparametros-importantes-de-gradient-boosting">
<h3>Hiperparámetros Importantes de Gradient Boosting<a class="headerlink" href="#hiperparametros-importantes-de-gradient-boosting" title="Link to this heading">#</a></h3>
<p>Gradient Boosting tiene varios hiperparámetros que pueden ajustarse para mejorar el rendimiento del modelo. Algunos de los hiperparámetros más importantes son:</p>
<ul class="simple">
<li><p><strong>n_estimators:</strong> Número de árboles de decisión que se utilizarán en el modelo. Un valor más alto de <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> puede mejorar la precisión del modelo, pero también aumenta el riesgo de sobreajuste.</p></li>
<li><p><strong>learning_rate:</strong> Tasa de aprendizaje que controla la contribución de cada árbol al modelo. Un valor más bajo de <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> requerirá más árboles para alcanzar la misma precisión, pero puede mejorar la generalización.</p></li>
<li><p><strong>max_depth:</strong> Profundidad máxima de cada árbol de decisión. Un valor más alto de <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> permitirá que los árboles sean más complejos, lo que puede llevar a un sobreajuste.</p></li>
<li><p><strong>subsample:</strong> Proporción de muestras utilizadas para entrenar cada árbol. Un valor más bajo de <code class="docutils literal notranslate"><span class="pre">subsample</span></code> puede reducir el riesgo de sobreajuste, pero también puede disminuir la precisión del modelo.</p></li>
</ul>
</section>
</section>
<section id="como-funcionan-las-redes-neuronales-artificiales">
<h2>Cómo Funcionan las Redes Neuronales Artificiales<a class="headerlink" href="#como-funcionan-las-redes-neuronales-artificiales" title="Link to this heading">#</a></h2>
<p>Las Redes Neuronales Artificiales (ANN) son un modelo de aprendizaje profundo inspirado en la estructura y el funcionamiento del cerebro humano. Estas redes están compuestas por capas de neuronas artificiales que se organizan en una arquitectura de red, con conexiones entre las neuronas que transmiten señales y aprenden a partir de los datos.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>El término “profundo” en el aprendizaje profundo se refiere a la presencia de múltiples capas ocultas en la red neuronal, lo que permite que el modelo aprenda representaciones jerárquicas de los datos.</p>
</div>
<section id="principios-fundamentales-de-las-redes-neuronales">
<h3>Principios Fundamentales de las Redes Neuronales<a class="headerlink" href="#principios-fundamentales-de-las-redes-neuronales" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Neuronas Artificiales:</strong> Las neuronas artificiales son unidades computacionales que reciben entradas, aplican una transformación no lineal a esas entradas y generan una salida. Cada neurona está conectada a otras neuronas a través de conexiones ponderadas.</p></li>
<li><p><strong>Capas de Neuronas:</strong> Las neuronas en una red neuronal se organizan en capas, que incluyen una capa de entrada, una o más capas ocultas y una capa de salida. Las capas ocultas permiten que la red aprenda representaciones complejas de los datos.</p></li>
<li><p><strong>Conexiones Ponderadas:</strong> Las conexiones entre las neuronas tienen pesos asociados que se ajustan durante el proceso de entrenamiento. Estos pesos determinan la importancia de las entradas para la salida de la neurona.</p></li>
</ol>
</section>
<section id="entrenamiento-de-redes-neuronales">
<h3>Entrenamiento de Redes Neuronales<a class="headerlink" href="#entrenamiento-de-redes-neuronales" title="Link to this heading">#</a></h3>
<p>El entrenamiento de una red neuronal implica dos fases clave: propagación hacia adelante (forward propagation) y retropropagación (backpropagation). Durante la propagación hacia adelante, las entradas se pasan a través de la red, y las salidas se calculan utilizando los pesos actuales. Durante la retropropagación, se calculan los gradientes de la función de pérdida con respecto a los pesos de la red, y estos gradientes se utilizan para ajustar los pesos a través de un proceso de optimización.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>El proceso de retropropagación es fundamental para el entrenamiento de redes neuronales, ya que permite que la red ajuste los pesos de manera que minimice la función de pérdida, mejorando así la precisión del modelo.</p>
</div>
</section>
<section id="aplicaciones-y-ventajas-de-las-redes-neuronales">
<h3>Aplicaciones y Ventajas de las Redes Neuronales<a class="headerlink" href="#aplicaciones-y-ventajas-de-las-redes-neuronales" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Visión por Computadora:</strong> Las redes neuronales convolucionales (CNN) son ampliamente utilizadas en tareas de visión por computadora, como la clasificación de imágenes y la detección de objetos.</p></li>
<li><p><strong>Procesamiento del Lenguaje Natural:</strong> Las redes neuronales recurrentes (RNN) y las redes neuronales transformadoras (Transformer) son efectivas en tareas de procesamiento del lenguaje natural, como la traducción automática y la generación de texto.</p></li>
<li><p><strong>Reconocimiento de Voz:</strong> Las redes neuronales son fundamentales en sistemas de reconocimiento de voz, como los asistentes virtuales y los sistemas de transcripción de voz a texto.</p></li>
<li><p><strong>Aprendizaje Profundo:</strong> Las redes neuronales son la base del aprendizaje profundo, un subcampo del aprendizaje automático que se centra en modelos de múltiples capas para aprender representaciones jerárquicas de los datos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Entrenamiento de una red neuronal</span>

<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        20
         1.0       0.00      0.00      0.00        20
         2.0       0.33      1.00      0.50        20

    accuracy                           0.33        60
   macro avg       0.11      0.33      0.17        60
weighted avg       0.11      0.33      0.17        60
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="conclusiones">
<h2>Conclusiones<a class="headerlink" href="#conclusiones" title="Link to this heading">#</a></h2>
<p>En este capítulo, exploramos varios modelos de clasificación supervisada, incluidos Support Vector Machines (SVM), Naive Bayes, Gradient Boosting y Redes Neuronales Artificiales. Cada uno de estos modelos tiene sus propias fortalezas y aplicaciones, y es importante comprender cómo funcionan y cuándo es apropiado utilizarlos.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Cuadernos"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Modelos%20de%20Clasificaci%C3%B3n%20I.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Primer resumen sobre modelos de clasificación supervisada</p>
      </div>
    </a>
    <a class="right-next"
       href="Ejercicio%20K%20Means.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Algoritmos Clúster</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-support-vector-machines-svm">Cómo Funciona Support Vector Machines (SVM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principios-fundamentales-de-svm">Principios Fundamentales de SVM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-algoritmo-svm">Visualización del Algoritmo SVM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-importantes-de-svm">Hipérparámetros Importantes de SVM</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-naive-bayes">Cómo Funciona Naive Bayes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentos-detallados-de-naive-bayes">Fundamentos Detallados de Naive Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-extendidas-de-naive-bayes">Aplicaciones Extendidas de Naive Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-intuitivo-y-visual">Ejemplo Intuitivo y Visual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-de-naive-bayes">Hiperparámetros de Naive Bayes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-gradient-boosting">Cómo Funciona Gradient Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principios-fundamentales-de-gradient-boosting">Principios Fundamentales de Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-algoritmo-gradient-boosting">Visualización del Algoritmo Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-y-ventajas-de-gradient-boosting">Aplicaciones y Ventajas de Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-importantes-de-gradient-boosting">Hiperparámetros Importantes de Gradient Boosting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funcionan-las-redes-neuronales-artificiales">Cómo Funcionan las Redes Neuronales Artificiales</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#principios-fundamentales-de-las-redes-neuronales">Principios Fundamentales de las Redes Neuronales</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entrenamiento-de-redes-neuronales">Entrenamiento de Redes Neuronales</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aplicaciones-y-ventajas-de-las-redes-neuronales">Aplicaciones y Ventajas de las Redes Neuronales</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones">Conclusiones</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Isaac Zainea
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>